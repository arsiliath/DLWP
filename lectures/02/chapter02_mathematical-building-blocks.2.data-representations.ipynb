{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a786a0-4a35-44e4-8f1a-b42286b33eab",
   "metadata": {
    "editable": true,
    "id": "2e4f93f7",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb45ee5-09d9-4877-889c-291a52e70595",
   "metadata": {
    "editable": true,
    "id": "2e4f93f7",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data representations for neural networks\n",
    "\n",
    "# Geometric Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1fd7a2be",
   "metadata": {
    "id": "1fd7a2be"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bff87d-46e5-41dc-a42a-7e52ba753ccb",
   "metadata": {
    "id": "153d74a4"
   },
   "source": [
    "# Action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a09188c-7e64-43f3-9fd3-1e64ce88ec9d",
   "metadata": {
    "id": "153d74a4",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. What are scalars, vectors, matrices, tensors\n",
    "2. What is the rank, the axis, the shape of a tensor\n",
    "3. Real examples of data tensors\n",
    "4. What is a (mini-)batch of data\n",
    "5. Tensor operations: arithmetic, slicing, broadcasting, reshaping, element-wise vs dot/matmul ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90153946-b879-46a7-b629-62ff78835566",
   "metadata": {
    "id": "26c4d9eb-ed4c-4123-a977-ff53d56261e7"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f37411-59a7-4d0e-a5e0-6d3d354c267a",
   "metadata": {
    "id": "26c4d9eb-ed4c-4123-a977-ff53d56261e7"
   },
   "source": [
    "# Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7c966-056a-436d-8f3f-d5fceff9fe2e",
   "metadata": {
    "id": "63ded2a8"
   },
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055f167-bdc1-48b0-b907-91cc1b90431d",
   "metadata": {
    "id": "63ded2a8"
   },
   "source": [
    "- 0 dimensional: **scalars**: plain numbers;\n",
    "- 1 dimensional: **vectors**:  arrays (in Python: lists/tuples);\n",
    "- 2 dimensional: **matrices**: multi-dimensional arrays â†’ NumPy/TF;\n",
    "- above: **tensors**: generalisation of matrices!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3592263f-69cd-434e-8abe-55498e1e15cc",
   "metadata": {
    "id": "9c042508-943c-4e68-ad71-862684a490b3"
   },
   "source": [
    "##### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f4eb0-f27a-4f11-b014-22e4f80e9dcb",
   "metadata": {
    "id": "9c042508-943c-4e68-ad71-862684a490b3"
   },
   "source": [
    "- Math: the **dimension** or **length** of the vector  is the **number of elements** in a vector. \n",
    "- Programming: the **dimension** of a tensor is the number of **axes** (or the *length* of the *shape*)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc24fc-fdba-4bea-b02a-fe9fc191b290",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798787c",
   "metadata": {
    "id": "5798787c"
   },
   "source": [
    "<!-- ![Figure showing scalar, 1D (vector) and 2D (matrix) tensors](images/tf/tf-shape-1.png) -->\n",
    "<img alt=\"Figure showing scalar, 1D (vector) and 2D (matrix) tensors\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/tf/tf-shape-1.png\">\n",
    "\n",
    "<small>Source: [TensorFlow Introduction to Tensors](https://www.tensorflow.org/guide/tensor)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd9fc4f",
   "metadata": {
    "id": "9fd9fc4f"
   },
   "source": [
    "<!-- ![Figure showing a 3D tensor in various transpositions](images/tf/tf-shape-2.png) -->\n",
    "<img alt=\"Figure showing a 3D tensor in various transpositions\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/tf/tf-shape-2.png\">\n",
    "\n",
    "<small>Source: [TensorFlow Introduction to Tensors](https://www.tensorflow.org/guide/tensor)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd35b3f1-40af-4bfe-a99d-6084cc55959a",
   "metadata": {
    "id": "fd35b3f1-40af-4bfe-a99d-6084cc55959a"
   },
   "source": [
    "<!-- ![Figure showing a 4D tensor](images/tf/tf-shape-3.png) -->\n",
    "<img alt=\"Figure showing a 4D tensor\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/tf/tf-shape-3.png\">\n",
    "\n",
    "<small>Source: [TensorFlow Introduction to Tensors](https://www.tensorflow.org/guide/tensor)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007b9a4f-0395-4438-b485-6c22e2fe9b2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "007b9a4f-0395-4438-b485-6c22e2fe9b2f",
    "outputId": "52fd202d-06f9-46f2-c3f3-6df2e547b44d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93, shape: (), rank: 0, 1 elements\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = np.array(93)\n",
    "print(f\"{x}, shape: {x.shape}, rank: {x.ndim}, {x.size} elements\") # rank: 0\n",
    "print()                                                            # the shape is an empty array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8189e42-56bb-4965-8032-704950a23f8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8189e42-56bb-4965-8032-704950a23f8f",
    "outputId": "115a1778-0d89-40c1-ad0e-08b9d2f6b2f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2], shape: (3,), rank: 1, 3 elements\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(3)\n",
    "print(f\"{x}, shape: {x.shape}, rank: {x.ndim}, {x.size} elements\") # rank: 1\n",
    "print()                                                            # shape with tuple syntax: (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c99113-b3d2-424e-a3b3-9a6bf233d3a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53c99113-b3d2-424e-a3b3-9a6bf233d3a8",
    "outputId": "fbc27f05-fc21-420e-a5c7-26437457ae0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]], shape: (2, 3), rank: 2, 6 elements\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(6).reshape((2,3))\n",
    "print(f\"{x}, shape: {x.shape}, rank: {x.ndim}, {x.size} elements\") # rank: 2\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d651733d-f137-4404-86e7-2185118b1952",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d651733d-f137-4404-86e7-2185118b1952",
    "outputId": "ca19e5c4-0eec-43ac-c61f-1988d88784d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]], shape: (2, 2, 3), rank: 3, 12 elements\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(12).reshape((2,2,3))\n",
    "print(f\"{x}, shape: {x.shape}, rank: {x.ndim}, {x.size} elements\") # rank: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a843d35d-ae53-4e27-863d-37795816be93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a843d35d-ae53-4e27-863d-37795816be93",
    "outputId": "41c8c4cd-df61-42ed-8749-065a185d4bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93, shape: (), rank: 0, 1 elements\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now in TensorFlow!\n",
    "x = tf.constant(93)                           # .size not included as a method by default in TF\n",
    "print(f\"{x}, shape: {x.shape}, rank: {x.ndim}, {tf.size(x)} elements\") # rank: 0\n",
    "print()                                                                # the shape is an empty array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3be3959-eef6-4051-9c4b-f94ea9cbb99f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3be3959-eef6-4051-9c4b-f94ea9cbb99f",
    "outputId": "f2fb9a82-1bc5-41e5-a7b0-11171a7bf787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2], shape: (3,), rank: 1, 3 elements\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.range(3)\n",
    "print(f\"{x}, shape: {x.shape}, rank: {x.ndim}, {tf.size(x)} elements\") # rank: 1\n",
    "print()                                                                # shape with tuple syntax: (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea509def-dd68-43d4-bd5d-1dd6761349bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea509def-dd68-43d4-bd5d-1dd6761349bd",
    "outputId": "b51bc8ed-c94a-4deb-ec1d-4465c38fbeb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]], shape: (2, 3), rank: 2, 6 elements\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.reshape(tf.range(6), (2,3)) # .reshape not included as a method by default in TF\n",
    "print(f\"{x}, shape: {x.shape}, rank: {x.ndim}, {tf.size(x)} elements\") # rank: 2\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af25b77a-9521-4cdd-a870-8d8f6ffc1ed6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af25b77a-9521-4cdd-a870-8d8f6ffc1ed6",
    "outputId": "b1bc0cb7-2a28-4d70-caaa-cf7ca1b82683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]], shape: (2, 2, 3), rank: 3, 12 elements\n"
     ]
    }
   ],
   "source": [
    "x = tf.reshape(tf.range(12), (2,2,3))\n",
    "print(f\"{x}, shape: {x.shape}, rank: {x.ndim}, {tf.size(x)} elements\") # rank: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6a686",
   "metadata": {
    "id": "11c6a686"
   },
   "source": [
    "A table of comparison between mathematics and programming:\n",
    "\n",
    "|Array |  Tensor | Maths |\n",
    "|:-----|:--------|:------|\n",
    "| 0D | rank 0 | scalar |\n",
    "| 1D | rank 1 | vector |\n",
    "| 2D | rank 2 | matrix |\n",
    "| 3D | rank 3 | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10798897-9a8a-47e7-a4e4-dc72f02c9d7c",
   "metadata": {
    "id": "e3f07323-ad86-44d7-b335-50d24c1c60ad"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90324fca-8c44-4c01-9fa7-b851bf90bcef",
   "metadata": {
    "id": "e3f07323-ad86-44d7-b335-50d24c1c60ad"
   },
   "source": [
    "## Key attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8ab70-0482-48c6-98d0-aa34620d9bce",
   "metadata": {
    "id": "e3f07323-ad86-44d7-b335-50d24c1c60ad"
   },
   "source": [
    "- **Axis** = each of the dimension of the tensor;\n",
    "- **Rank** = **dimension** = number of axes (and indices needed to retrieve elements);\n",
    "- **Shape** = a description of the dimensions (size of each axis);\n",
    "- **Type** = the data type of the contained data â€“ `float32`, `uint8`..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28465b1-7ad9-431d-939c-fe200fe787c2",
   "metadata": {
    "id": "0b3e92d1"
   },
   "source": [
    "### Beware!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e573cdd-5794-4991-90e2-8143cc7a65c1",
   "metadata": {
    "id": "0b3e92d1"
   },
   "source": [
    "The NumPy and TensorFlow APIs are quite similar, with yet small differences here and there, leading to confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baa759a-2524-419e-90dd-132c0e375576",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2baa759a-2524-419e-90dd-132c0e375576",
    "outputId": "4b9f7691-0581-4686-8f0a-fe1ddb79393e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beware!\n",
      "\n",
      "The default NumPy type: int64\n",
      "\n",
      "The default TensorFlow type: <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Beware!\")\n",
    "print()\n",
    "\n",
    "x = np.arange(12).reshape((2,2,3))\n",
    "print(f\"The default NumPy type: {x.dtype}\")\n",
    "print()\n",
    "\n",
    "x = tf.reshape(tf.range(12), (2,2,3))\n",
    "print(f\"The default TensorFlow type: {x.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe07d5-05b7-4049-8901-8b5161c7e974",
   "metadata": {
    "id": "4958c16f-1395-4a1b-aaec-17ae7d52e86e"
   },
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c126762b-1455-4e8d-a5e8-baa447214fb7",
   "metadata": {
    "id": "4958c16f-1395-4a1b-aaec-17ae7d52e86e"
   },
   "source": [
    "|                        |        |\n",
    "|-----------------------:|:-------|\n",
    "| multidimensional array | tensor |\n",
    "| dimension              | axis   |\n",
    "| number of dimensions   | rank  \n",
    "| length | number of elements in a 1D array/along a tensor axis |\n",
    "| size | total number of elements (= rows * cols, for a matrix) |\n",
    "| shape | lengths of each axis |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e23303-dadb-4ae6-915c-9d5851fcf83c",
   "metadata": {
    "id": "f440fffb-1106-4b3a-a3f5-d2cf15b299ed"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65559ef4-2ca9-4415-a7b9-60d31d5418f1",
   "metadata": {
    "id": "f440fffb-1106-4b3a-a3f5-d2cf15b299ed"
   },
   "source": [
    "## Manipulating tensors in NumPy (slicing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4de6c9-065d-4779-aa05-acf457e4735a",
   "metadata": {
    "id": "f440fffb-1106-4b3a-a3f5-d2cf15b299ed"
   },
   "source": [
    "Data frames are pulled from tensors by an operation known as **slicing**.\n",
    "\n",
    "This is one of the things you cannot do in plain Python (you'd need loops and they are **slow**)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494edcc-d117-4ed2-8839-92b7825cfdb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4afcd862-c218-4da9-9672-0a7808aef543",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4afcd862-c218-4da9-9672-0a7808aef543",
    "outputId": "6bd69c2b-fd37-4e7c-8a59-d630c627e0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]]\n"
     ]
    }
   ],
   "source": [
    "# a rank 3 tensor\n",
    "x = np.array([[[1, 2],\n",
    "               [3, 4]],\n",
    "\n",
    "              [[5, 6],\n",
    "               [7, 8]],\n",
    "\n",
    "              [[9, 10],\n",
    "               [11, 12]]])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd54eb18-520f-442a-a010-6cdeeac665a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd54eb18-520f-442a-a010-6cdeeac665a0",
    "outputId": "e55049aa-50d6-4594-fceb-c360d94075db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(x[0])       # first element of the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d82ef74-c8e1-41b3-ae12-4744d93819a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d82ef74-c8e1-41b3-ae12-4744d93819a7",
    "outputId": "2e6c6a0c-29dc-42dc-a428-78680726f5db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "print(x[0, 0])    # first row of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bfa0e68-7a45-4a0d-a998-1e971b1dbc66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bfa0e68-7a45-4a0d-a998-1e971b1dbc66",
    "outputId": "78f09b26-4277-4513-a07b-3c5083c8d8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x[0, 0, 0]) # first element of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b18b85-7302-4e1c-a6fb-ae8a666ca27a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14b18b85-7302-4e1c-a6fb-ae8a666ca27a",
    "outputId": "40ce34b9-632a-4408-fb45-a8270bad90e2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1]\n",
      "  [ 2  3]]\n",
      "\n",
      " [[ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(12).reshape((3,2,2))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5cfe035-8475-4586-892f-b49bd2a1ef91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5cfe035-8475-4586-892f-b49bd2a1ef91",
    "outputId": "dc241d16-46ad-4fd7-8379-98299d76a941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [4 5]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "               # for each of the blocks, the first row\n",
    "print(x[:, 0]) # ':' means \"everything in this axis/dimension\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dedb6d6-c8c4-49df-968a-95bb5d7d4198",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dedb6d6-c8c4-49df-968a-95bb5d7d4198",
    "outputId": "d097e42a-aca3-4e8c-d5e4-d10acd936bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2]\n",
      " [ 4  6]\n",
      " [ 8 10]]\n"
     ]
    }
   ],
   "source": [
    "# for each of the blocks, the first column\n",
    "# (for each block, for each column, the first element)\n",
    "print(x[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f84f8583-6a78-454d-b99e-16e8d8b89d9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f84f8583-6a78-454d-b99e-16e8d8b89d9f",
    "outputId": "0f8ca2f1-8c05-4f75-a9f4-61d7ed632698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2]\n",
      " [ 4  6]\n",
      " [ 8 10]]\n"
     ]
    }
   ],
   "source": [
    "print(x[..., 0])  # same as above: '...' means: \"fill in the rest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04bce0c-a6bf-46a5-92f1-3961253f142a",
   "metadata": {
    "id": "36b5dd4d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa82d1-48ec-4d28-92d4-b7b23b981ee0",
   "metadata": {
    "id": "36b5dd4d"
   },
   "source": [
    "## The notion of data batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2268b8-106c-4c32-af51-61be3fb923bf",
   "metadata": {
    "id": "36b5dd4d"
   },
   "source": [
    "Slicing is particularly present when preparing data.\n",
    "\n",
    "Datasets are rarely processed in one go, it's intractable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7312a6",
   "metadata": {
    "id": "1f7312a6"
   },
   "source": [
    "Instead, data is broken up into **mini-batches**:\n",
    "\n",
    "- `train_images[:128]` a mini-batch of the first 128 images;\n",
    "- `train_images[128:256]` the second mini-batch;\n",
    "- `train_images[128 * n, 128 * (n + 1)]` the $n+1$'th mini-batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e846289",
   "metadata": {
    "id": "0e846289"
   },
   "source": [
    "Slicing MNIST image tensors about the first axis selects contiguous images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9fcc94-414e-4ed6-b86a-37d2cb0d17f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b9fcc94-414e-4ed6-b86a-37d2cb0d17f6",
    "outputId": "b03c072b-192d-407a-8d0e-36ba42f139c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'[60'000 images, width, height]'\n",
      "shape (60000, 28, 28)\n",
      "rank: 3\n",
      "dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "print(\"'[60'000 images, width, height]'\")\n",
    "print(\"shape\", train_images.shape)  # each axis & number of elements\n",
    "print(\"rank:\", train_images.ndim)   # rank = ndim = len(shape)\n",
    "print(\"dtype:\", train_images.dtype) # data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6928e3ee-6a32-434d-8bd2-242e369639bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6928e3ee-6a32-434d-8bd2-242e369639bf",
    "outputId": "9b366726-8bf4-4c2b-98ef-f9088d44fee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:20]   # select images 10 through to image 19\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ae1e9-ba97-43b3-8ce5-73489707366c",
   "metadata": {
    "id": "3e413f72"
   },
   "source": [
    "### Slicing can happen *inside* the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20751e6-1a26-45f8-83e7-1c308e9d0005",
   "metadata": {
    "id": "3e413f72"
   },
   "source": [
    "Imagine we wish to extract the middle 14 by 14 sub-image of every test image. Easy with slicing!\n",
    "\n",
    "`7:-7` from element 7 **up to, but not including**, element 21 (= 28 - 7).\n",
    "\n",
    "\n",
    "0, ..., 6,|7, ..., 20|, 21, ..., 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aa22552-0c8f-4da5-9595-3a54970657fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aa22552-0c8f-4da5-9595-3a54970657fd",
    "outputId": "359cf022-f9ef-47b7-ecb1-3f5c5bc0f6bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the middle 14 x 14 subimages from all test images\n",
    "                 # slicing width, height\n",
    "my_slice = train_images[:, 7:-7, 7:-7] # : on its own means 'everything'\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88fbb6-daf0-46eb-a073-19888f5dfd7e",
   "metadata": {
    "id": "4ccbadfb-dd48-4af3-ac62-fe3307b4fa59"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3f47f-1231-4478-a30a-826a046286a2",
   "metadata": {
    "id": "4ccbadfb-dd48-4af3-ac62-fe3307b4fa59"
   },
   "source": [
    "## Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3302cb18-f5d9-4b25-b7ec-40a7c4a850ff",
   "metadata": {
    "id": "4ccbadfb-dd48-4af3-ac62-fe3307b4fa59"
   },
   "source": [
    "Let's look at some examples of real data tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6ced0-a239-4312-9968-96a7814dbc54",
   "metadata": {
    "id": "49cfcddd-18f7-4941-90d0-c1b2d99d86fe"
   },
   "source": [
    "### Rank 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8f799-5b4f-4314-9eb4-714faf584639",
   "metadata": {
    "id": "49cfcddd-18f7-4941-90d0-c1b2d99d86fe"
   },
   "source": [
    "Say we collected data on a population â€“ for example, postcode, age, income.\n",
    "\n",
    "The samples axis, the first axis, is each person surveyed and for each person we collect a vector of information, and the second axis is the data taken as a whole.\n",
    "\n",
    "|  Data  | Rank | Shape     | Example    |\n",
    "|---:|:---:|:---:|:----|\n",
    "| vector | 2 | `(num_samples,num_features)` | demographics of a population - (postcode, age, income,...) for each person |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8ccb56-9ae9-4bd2-91e3-cf49086af8b1",
   "metadata": {
    "id": "a3afe153-649f-4822-b7c6-37a3ffc24e01"
   },
   "source": [
    "### Rank 3: time series, sequences (text/music)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e00c7-8a18-48de-b22e-883b914c4392",
   "metadata": {
    "id": "a3afe153-649f-4822-b7c6-37a3ffc24e01"
   },
   "source": [
    "Example of time series data: a data-set of weather readings.\n",
    "\n",
    "A series of measurements â€“ precipitation, temperature, etc. â€“ at ten minutes intervals is collected for each day or sample.\n",
    "\n",
    "|  Data  | Rank | Shape     | Example    |\n",
    "|---:|:---:|:---:|:----|\n",
    "| timeseries or sequence| 3 | `(num_samples,num_timesteps,num_features)` | daily weather features at ten minute intervals â€“ (precipitation, temperature, humidity) for each time for each day |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb0b38-54f7-46da-a40f-4c9eea975acc",
   "metadata": {
    "id": "98a8ace3-aeb6-40ee-9e07-21340c3fb8a4"
   },
   "source": [
    "### Rank 4: colour images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbf6e1-e162-4c62-a3ae-a749bf2212c9",
   "metadata": {
    "id": "98a8ace3-aeb6-40ee-9e07-21340c3fb8a4"
   },
   "source": [
    "A colour image data-set is an example of rank 4 information.\n",
    "\n",
    "An RGB vector resides at each pixel. The samples are individual images.\n",
    "\n",
    "|  Data  | Rank | Shape     | Example    |\n",
    "|---:|:---:|:---:|:----|\n",
    "| image | 4 | `(num_samples,width,height,channels)` | 10,000 colour 256 x 256 colour images â€“ a (256, 256, 3) colour map for each image|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f2b406-be35-401d-8131-c61483c831df",
   "metadata": {
    "id": "98a8ace3-aeb6-40ee-9e07-21340c3fb8a4",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d111d-b503-4fb4-91c3-8e7d04ad312e",
   "metadata": {
    "id": "98a8ace3-aeb6-40ee-9e07-21340c3fb8a4"
   },
   "source": [
    "In some formats (PyTorch) you encounter  `(num_samples,channels,width,height)` instead! ðŸ’€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9f9ac-c949-4c32-bc20-b2233d00922b",
   "metadata": {
    "id": "aade3b18-6459-405c-ae4a-72d948653771"
   },
   "source": [
    "### Rank 5: video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f16ba9-95ee-4e53-95dd-fcda5b86f3b2",
   "metadata": {
    "id": "aade3b18-6459-405c-ae4a-72d948653771"
   },
   "source": [
    "About as high as you will ever meet.\n",
    "\n",
    "The samples are videos: a video is a time series of frames and each frame is a 2D colour image.\n",
    "\n",
    "|  Data  | Rank | Shape     | Example    |\n",
    "|---:|:---:|:---:|:----|\n",
    "| video | 5 | `(num_samples,num_frames,width,height,channels)` | video â€“ a (256, 256, 3) colour map for each frame of each video|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea22816-a080-47eb-94ef-13b3aea60089",
   "metadata": {
    "id": "c5ca25a3-5fee-4d73-a32b-6247cb72e963"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7740843-86a0-4c98-b61e-abab56edd3f8",
   "metadata": {
    "id": "c5ca25a3-5fee-4d73-a32b-6247cb72e963"
   },
   "source": [
    "# The gear of neural networks: Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f5404-90ab-47e9-80f2-d26a36bdfeed",
   "metadata": {
    "id": "c5ca25a3-5fee-4d73-a32b-6247cb72e963"
   },
   "source": [
    "- Element-wise operations\n",
    "- Broadcasting\n",
    "- Tensor product\n",
    "- Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb5961-39fe-48c3-9cd4-777e9bf6b81d",
   "metadata": {
    "id": "1c9dba80"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6925a01-70c1-4c29-b4b0-a3f332eff090",
   "metadata": {
    "id": "1c9dba80"
   },
   "source": [
    "## Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ba6bd-fc73-4939-8e68-126e01a88386",
   "metadata": {
    "id": "1c9dba80"
   },
   "source": [
    "Element-wise means: per-element operation.\n",
    "\n",
    "- Shapes must be **the same**;  \n",
    "- **Or** compatible so that unequal axes can be **broadcast**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f1b76-460f-481c-a617-95f768f05f7e",
   "metadata": {
    "id": "1e3f1b76-460f-481c-a617-95f768f05f7e"
   },
   "source": [
    "Element-wise addition:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\left(\\begin{array}{c} 3 \\\\ 4 \\end{array} \\right)\n",
    "+ \\left( \\begin{array}{c} 8 \\\\ 9 \\end{array} \\right)\n",
    "= \\left( \\begin{array}{c} 11 \\\\ 13 \\end{array} \\right)\n",
    "\\end{eqnarray}\n",
    "\n",
    "Hadamard product (point-wise multiplication):\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\left(\\begin{array}{c} 3 \\\\ 4 \\end{array} \\right)\n",
    "\\odot \\left( \\begin{array}{c} 8 \\\\ 9 \\end{array} \\right)\n",
    "= \\left( \\begin{array}{c} 24 \\\\ 36 \\end{array} \\right)\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "927a51c7-7209-4da9-8dcc-dea7689d1717",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "927a51c7-7209-4da9-8dcc-dea7689d1717",
    "outputId": "bfaeec67-f140-4f45-9051-de9307f99288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 13]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3, 4])\n",
    "y = np.array([8, 9])\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebeb934-88a5-495d-9bc9-443402989b40",
   "metadata": {
    "id": "0ebeb934-88a5-495d-9bc9-443402989b40"
   },
   "source": [
    "Element-wise function application: the function is applied to each element.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "  f\\left( \\begin{array}{c} -2 \\\\ 3 \\end{array} \\right)\n",
    "  = \\left( \\begin{array}{c} f(-2) \\\\ f(3) \\end{array} \\right)\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "For instance, the `ReLU` activation:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "  \\texttt{relu}\\left( \\begin{array}{c} -2 \\\\ 3 \\end{array} \\right)\n",
    "   = \\left( \\begin{array}{c} \\texttt{relu}(-2) \\\\ \\texttt{relu}(3) \\end{array} \\right)\n",
    "   = \\left( \\begin{array}{c} 0 \\\\ 3 \\end{array} \\right)\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43324477-2a4d-4007-a4f9-d48dd30202d1",
   "metadata": {
    "id": "43324477-2a4d-4007-a4f9-d48dd30202d1"
   },
   "outputs": [],
   "source": [
    "# simple definition of a relu function for rank 1 tensors\n",
    "def relu(x):\n",
    "    assert len(x.shape) == 1\n",
    "    y = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        y[i] = max(y[i], 0.)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d184504-9d38-442f-bd98-3d4c2fb062f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d184504-9d38-442f-bd98-3d4c2fb062f2",
    "outputId": "33a03d40-5589-422b-ba35-91f0a0239ca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3]\n",
      "tf.Tensor([0 3], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-2, 3])\n",
    "print(relu(x))\n",
    "print(tf.nn.relu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f56498-5b62-437a-bc6b-5db2258841c1",
   "metadata": {
    "id": "35f56498-5b62-437a-bc6b-5db2258841c1"
   },
   "source": [
    "**Important: *element-wise* stands in opposition to the *tensor product*, coming in a minute.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbdc365-f546-46aa-81c0-beddfdb75f6a",
   "metadata": {
    "id": "664b83fa-575e-48fc-8537-a6ed5f83b9ba"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f714903-9bf0-41d8-9fc9-c17cc3993a12",
   "metadata": {
    "id": "664b83fa-575e-48fc-8537-a6ed5f83b9ba"
   },
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240924f-55f9-44f3-815f-af2ac2bd02f2",
   "metadata": {
    "id": "0f43a25c-88f5-4f30-8fe2-b077cd11057c",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**General broadcasting rules**\n",
    "\n",
    "1. Tensor shapes are compared right to left: **right-align the axes**;\n",
    "2. If needed, **add empty dimensions** (1s) to the left so that the **ranks** are equal.\n",
    "3. a. Dimensions are compatible if they are **equal** or **one of them is 1**;  \n",
    "   b. The axis with dimension 1 is **copied** (\"stretched\", \"broadcast\") to match the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086502ef-20c6-4fc3-b1dd-5b3a3f32f9ca",
   "metadata": {
    "id": "086502ef-20c6-4fc3-b1dd-5b3a3f32f9ca"
   },
   "source": [
    "<!-- ![Numpy broadcasting: 1D array with scalar -> 1D array](images/tf/np_broadcasting_1.png) -->\n",
    "<img alt=\"Numpy broadcasting: 1D array with scalar -> 1D array\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/tf/np_broadcasting_1.png\">\n",
    "\n",
    "<small>Source: [NumPy Broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2772b-9a6d-46f3-a08b-5d83cfd9903a",
   "metadata": {
    "id": "39b2772b-9a6d-46f3-a08b-5d83cfd9903a"
   },
   "source": [
    "<!-- ![Numpy broadcasting: 2D array with 1D array -> 2D array](images/tf/np_broadcasting_2.png) -->\n",
    "<img alt=\"Numpy broadcasting: 2D array with 1D array -> 2D array\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/tf/np_broadcasting_2.png\">\n",
    "\n",
    "<small>Source: [NumPy Broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7011159c-f7a1-40e5-b8cd-19117387cc19",
   "metadata": {
    "id": "7011159c-f7a1-40e5-b8cd-19117387cc19"
   },
   "source": [
    "This does not work, why? Because you first **align the dimension to the right**: `(4,3)` and `(4,) â†’ (1,4)`!\n",
    "\n",
    "<!-- ![Numpy broadcasting mismatch: 2D array (4x3) with 1D (4) -> incompatible (3 is not equal to 4, and neither is 1)](images/tf/np_broadcasting_3.png) -->\n",
    "<img alt=\"Numpy broadcasting mismatch: 2D array (4x3) with 1D (4) -> incompatible (3 is not equal to 4, and neither is 1)\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/tf/np_broadcasting_3.png\">\n",
    "\n",
    "<small>Source: [NumPy Broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43341583-1639-4ee5-be66-a2d797946da1",
   "metadata": {
    "id": "43341583-1639-4ee5-be66-a2d797946da1"
   },
   "source": [
    "Double broadcasting: `(4,1)` and `(3,) â†’ (1,3)`\n",
    "\n",
    "<!-- ![Numpy broadcasting: 2D array (4x1) with 1D array (3) works: result is 2D (4x3)](images/tf/np_broadcasting_4.png) -->\n",
    "<img alt=\"Numpy broadcasting: 2D array (4x1) with 1D array (3) works: result is 2D (4x3)\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/tf/np_broadcasting_4.png\">\n",
    "\n",
    "<small>Source: [NumPy Broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b123355-70b0-4396-84f0-3007ce5b5690",
   "metadata": {
    "id": "3b123355-70b0-4396-84f0-3007ce5b5690"
   },
   "source": [
    "<!-- ![Sasha Rush broadcasting rules: 1) dims right aligned; 2) assign 1s to missing dimensions; 3) check compatibility, dims must be the same or one must be one; 4) broadcast by copying dims that are 1 to the number of the other dim](images/tf/srush-broadcasting.png) -->\n",
    "<img alt=\"Sasha Rush broadcasting rules: 1) dims right aligned; 2) assign 1s to missing dimensions; 3) check compatibility, dims must be the same or one must be one; 4) broadcast by copying dims that are 1 to the number of the other dim\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/tf/srush-broadcasting.png\">\n",
    "\n",
    "<small>Source: [Sasha Rush, Twitter](https://twitter.com/srush_nlp/status/1516781757596680194?t=RwVp5kUWPvHG-e42wo0ryw&s=19)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addab412-2c5b-4cf4-befd-08029444008b",
   "metadata": {
    "id": "92aeb7a9"
   },
   "source": [
    "##### Beware!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d8f63-20b7-40e8-ab57-0e6664d9d2c5",
   "metadata": {
    "id": "92aeb7a9"
   },
   "source": [
    "This is an extremely useful functionality, but *sometimes* that's not what you want!\n",
    "\n",
    "As a rule of thumb, **you cannot be too careful** about your shapes and tensor operations.\n",
    "\n",
    "**It takes practice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8d7fb-35e7-4d48-9453-012969280f30",
   "metadata": {
    "id": "f8f87794-55d5-42c3-a6a5-84119aef37bd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a795de9-859b-4203-b329-af57c7cefa32",
   "metadata": {
    "id": "f8f87794-55d5-42c3-a6a5-84119aef37bd"
   },
   "source": [
    "## Tensor product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f600ca-2a08-44df-905c-a981c59b5869",
   "metadata": {
    "id": "f8f87794-55d5-42c3-a6a5-84119aef37bd"
   },
   "source": [
    "The dot operation is the tensor analogue of the dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1926b2-e53f-49b3-87b5-a2c39ef267a0",
   "metadata": {
    "id": "6c1926b2-e53f-49b3-87b5-a2c39ef267a0"
   },
   "source": [
    "- between vectors, the familiar dot or scalar product:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\left( \\begin{array}{c} 2 & 3 \\end{array} \\right)\n",
    "\\cdot\n",
    "\\left( \\begin{array}{c}  -1  \\\\ 2  \\end{array} \\right) =\n",
    "4\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b64e38af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b64e38af",
    "outputId": "6b9b339c-e595-4b05-d1dc-58f0bd9e5a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2,3])\n",
    "y = np.array([-1,2])\n",
    "print(x.dot(y))\n",
    "print(tf.reduce_sum(x*y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14b156-eaef-47f0-b4e5-bdf9834bd9ad",
   "metadata": {
    "id": "cb14b156-eaef-47f0-b4e5-bdf9834bd9ad"
   },
   "source": [
    "- between a matrix and a vector:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\left( \\begin{array}{cc} 2 & 3  \\\\ 4 & 5  \\end{array} \\right)\n",
    "\\cdot\n",
    "\\left( \\begin{array}{c}  -1  \\\\ 2  \\end{array} \\right) =\n",
    "\\left( \\begin{array}{c}  4  \\\\ 6  \\end{array} \\right)\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf008751",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf008751",
    "outputId": "ea67cf08-0e7a-4793-e030-ccb7deaa1f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n",
      "tf.Tensor(\n",
      "[[4]\n",
      " [6]], shape=(2, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[2,3],[4,5]])\n",
    "y = np.array([-1,2])\n",
    "print(x.dot(y))\n",
    "print(x @ tf.reshape(y, (-1,1))) # turn y into a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a285c7c-d1b9-4db0-b2e5-401ad1a9dfde",
   "metadata": {
    "id": "0a285c7c-d1b9-4db0-b2e5-401ad1a9dfde"
   },
   "source": [
    "- between matrices:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\left( \\begin{array}{cc} 2 & 3  \\\\ 4 & 5  \\end{array} \\right)\n",
    "\\cdot\n",
    "\\left( \\begin{array}{cc}  -1  & 2 \\\\ 2 & -3  \\end{array} \\right) =\n",
    "\\left( \\begin{array}{cc}  4 & -5  \\\\ 6 & -7  \\end{array} \\right)\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e2efaac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e2efaac",
    "outputId": "2e11a632-c717-4929-a2eb-f5f4cb20b6ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 -5]\n",
      " [ 6 -7]]\n",
      "[[ 4 -5]\n",
      " [ 6 -7]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[2,3],[4,5]])\n",
    "y = np.array([[-1,2], [2, -3]])\n",
    "print(x.dot(y))\n",
    "print(x @ y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993fa49-5dd4-4d19-8fa5-d4bd90ba62d5",
   "metadata": {},
   "source": [
    "### Note: inner dimensions must match!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ac5e4-0b79-4909-8e43-8796e8b791b2",
   "metadata": {},
   "source": [
    "$$\n",
    "( { \\color{blue} m } \\times { \\color{orange} n })\\cdot ( {\\color{orange} n } \\times { \\color{green}  k } ) \\rightarrow ( { \\color{blue} m } \\times { \\color{green} k } )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c85fd3-bc3d-41c4-b6c7-2dc36d501aa7",
   "metadata": {
    "id": "df25239f-955d-4814-be59-d3ed2d1d07c5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011367f5-e352-4be3-9b4d-c7d9df413db1",
   "metadata": {
    "id": "df25239f-955d-4814-be59-d3ed2d1d07c5"
   },
   "source": [
    "## Tensor reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29e6d5-8bd8-4e41-8990-2563a219945a",
   "metadata": {
    "id": "df25239f-955d-4814-be59-d3ed2d1d07c5"
   },
   "source": [
    "As we have seen, tensors elements can be redistributed in an operation known as **reshaping**.\n",
    "\n",
    "For instance, the original `(60000, 28, 28)` MNIST images were flattened to `(60000, 28*28)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08b95d97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08b95d97",
    "outputId": "91e5ab80-1bdf-495c-f8d8-2d18f1c6cf22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (60000, 28, 28), after reshape: (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_images_reshaped = train_images.reshape((60000, 28 * 28))\n",
    "print(f\"train_images shape: {train_images.shape}, after reshape: {train_images_reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6e59a-5833-455d-8447-f23663cc03ea",
   "metadata": {
    "id": "65d6e59a-5833-455d-8447-f23663cc03ea"
   },
   "source": [
    "**Transposition** is another possibility.\n",
    "\n",
    "Transposition flips rows and columns along the main diagonal.\n",
    "\n",
    "Used all the time to make tensor dimensions agree for the tensor product!\n",
    "\n",
    "<!-- <img alt=\"GIF showing the transposition of a matrix\" style=\"height: 500px; float:right\" src=\"images/matrix-transpose.wiki.gif\"> -->\n",
    "<img alt=\"GIF showing the transposition of a matrix\" style=\"height: 500px; float:right\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/matrix-transpose.wiki.gif\">\n",
    "\n",
    "\n",
    "<small style=\"position: absolute; bottom:0; right:0\">[Transpose, Wikipedia](https://en.wikipedia.org/wiki/Transpose)</small>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3e63554-31ad-4bc6-b5ab-1a4732afe6c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3e63554-31ad-4bc6-b5ab-1a4732afe6c0",
    "outputId": "4d92db1a-7d3a-42ee-eaf4-23495738808a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      "[[0 3]\n",
      " [1 4]\n",
      " [2 5]]\n",
      "\n",
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[0 3]\n",
      " [1 4]\n",
      " [2 5]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(6).reshape((2,3))\n",
    "print(x)\n",
    "print()\n",
    "print(x.T) # same as x.transpose()\n",
    "print()\n",
    "\n",
    "x = tf.reshape(tf.range(6), (2,3))\n",
    "print(x)\n",
    "print()\n",
    "print(tf.transpose(x)) # as before, TF has functional equivalents\n",
    "                       # no x.T in TF!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315605fd-dae7-47cc-801d-3be0cbc32a3c",
   "metadata": {
    "id": "aea001a7"
   },
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b7e0d-63fc-47cb-8691-319ebe61d7d7",
   "metadata": {
    "id": "aea001a7"
   },
   "source": [
    "1. What are scalars, vectors, matrices, tensors  \n",
    "2. What is the rank, the axis, the shape of a tensor  \n",
    "3. Real examples of data tensors  \n",
    "4. What is a (mini-)batch of data  \n",
    "5. Tensor operations: arithmetic, slicing, broadcasting, reshaping, element-wise vs dot/matmul ops  \n",
    "\n",
    "**Practice Makes Perfect!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b33e4-fa86-4457-8fe4-cb63c9e98b45",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8016fd2-5967-45a5-a450-0a44c7633afa",
   "metadata": {
    "id": "f53db60c-4d57-4cb2-aeed-850e43862a8d"
   },
   "source": [
    "# Dense Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097a566-a5c2-4b7b-8123-e474809e0ada",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "We have seen the fundamental operation:\n",
    "\n",
    "$$\n",
    "\\bbox[5px,border:2px solid red]{\n",
    "    \\sigma(Wx + b) = a\n",
    "}\n",
    "$$\n",
    "\n",
    "$W$: weight (matrix)  \n",
    "$x$: input  \n",
    "$b$: bias (vector)  \n",
    "$\\sigma$: activation  \n",
    "$a$: output (matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f9dd1-bcb1-4eec-a833-8085301f9f59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13a5b5-7673-4ad3-84ec-bc8ff976cbd7",
   "metadata": {},
   "source": [
    "[In practice](https://github.com/keras-team/keras/blob/ad27d9ccefa97ec0496ec3ffaa1df5d731acd636/keras/src/layers/core/dense.py#L212), it's implemented as ... $\\sigma(xW + b)$, thank you very much..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff74c6e9-33ad-472b-83a3-ee0d62591d3b",
   "metadata": {},
   "source": [
    "## Graphs & Math notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047ee3b-d054-41e4-b529-a1d17ca8cb95",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### 1. One input (two features), one neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e5a4c-4123-4def-a63f-b86e4594df85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "\\newcommand\\mycolv[1]{\\begin{bmatrix}#1\\end{bmatrix}}\n",
    "   \\sigma\\left( \\mycolv{x_{1} & x_{2}}\\mycolv{w_{11}\\\\ w_{12}}  + b_1 \\right) = a_1\n",
    "$$\n",
    "\n",
    "\n",
    "<!-- <img style=\"\" src=\"images/nn/nn.2.svg\"> -->\n",
    "<img style=\"float:left\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/d942b064df6d0e929cbd027bc6a6939f9e8fc763/3-getting-started/images/nn/nn.2.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e220bb12-40fd-4dad-96ad-49a03e29cdfb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### 2. One input (two features), two neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535eef41-7beb-4403-aad2-a1e06535bee2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can do these two operations in one fell swoop using matrix multiplication.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\sigma \\left(\n",
    "\\underbrace{\n",
    "\\underbrace{\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} x_1  & x_2  \\end{bmatrix}\n",
    "}_{ \\text{shape: } (1,2) }\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} w_{11} & w_{12} \\\\  w_{21} & w_{22} \\end{bmatrix} \n",
    "}_{ (2, 2) }\n",
    "}_{ (1, 2) }\n",
    "+\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} b_1  & b_2 \\end{bmatrix}\n",
    "}_{ (1,2) }\n",
    "}_{ (1,2) }\n",
    "\\right)\n",
    "=\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} a_1  & a_2 \\end{bmatrix} \n",
    "}_{ (1,2) }\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "<!-- <img style=\"\" src=\"images/nn/nn.3.svg\"> -->\n",
    "\n",
    "<img style=\"float:left\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/d942b064df6d0e929cbd027bc6a6939f9e8fc763/3-getting-started/images/nn/nn.3.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6954c6-3f56-42e7-a9a4-4085742e0b1a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### 3. One input (two features), `n` neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8c56a-6993-44ea-8a07-00df750c63a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\\begin{eqnarray}\n",
    "\\sigma \\left(\n",
    "\\underbrace{\n",
    "\\underbrace{\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} x_1  & x_2  \\end{bmatrix}\n",
    "}_{ \\text{shape: }  (1, 2) }\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} w_{11} & \\cdots & w_{1n} \\\\ \\\\ w_{21} & \\cdots  & w_{2n} \\end{bmatrix}\n",
    "}_{ (2, n) }\n",
    "}_{ (1, n) }\n",
    "+\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} b_1 & \\cdots & b_n \\end{bmatrix} \n",
    "}_{ (1, n) }\n",
    "}_{ (1, n) }\n",
    "\\right) = \n",
    "\\underbrace{\n",
    "\\begin{bmatrix} a_1 & \\cdots & a_n \\end{bmatrix} \n",
    "}_{ (1, n) }\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "Example with $n = 12$:\n",
    "\n",
    "<!-- <img style=\"\" src=\"images/nn/nn.4.svg\"> -->\n",
    "\n",
    "<img style=\"float:left\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/d942b064df6d0e929cbd027bc6a6939f9e8fc763/3-getting-started/images/nn/nn.4.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb23446-5f5a-43f1-bbf0-4e77f93e779d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### 4. Mini-batch of `m` inputs (two features), `n` neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c879dd-bcad-4373-aa79-aea41d3e2066",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\\begin{eqnarray}\n",
    "\\sigma \\left(\n",
    "\\underbrace{\n",
    "\\underbrace{\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} x_{11} &  x_{12} \\\\ \\vdots & \\vdots \\\\ x_{m1} & x_{m2}  \\end{bmatrix}\n",
    "}_{ \\text{shape: } (m, 2) }\n",
    "\\underbrace{\n",
    "\\begin{bmatrix} w_{11} & \\cdots & w_{1n} \\\\ w_{21} & \\cdots &  w_{2n} \\end{bmatrix}\n",
    "}_{ (2, n) }\n",
    "}_{ (m, n) }\n",
    "+\n",
    "\\underbrace{ \\begin{bmatrix} b_1 & \\cdots & b_n \\end{bmatrix} }_{ (1, n) }\n",
    "}_{ \\text{ broadcasting: } \\rightarrow (m, n) }\n",
    "\\right) = \n",
    "\\underbrace{\n",
    "\\begin{bmatrix} a_{11} & \\cdots & a_{1n} \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} & \\cdots & a_{mn} \\end{bmatrix} \n",
    "}_{ (m, n)}\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6852f1e4-8f00-4d28-a9ea-057f634c9364",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Extra: Sum notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1d718-fb2d-47d8-a165-ea39c75b0e4e",
   "metadata": {
    "id": "f53db60c-4d57-4cb2-aeed-850e43862a8d"
   },
   "source": [
    "The first layer of our MNIST network performed `relu(dot(w, x) + b)`.\n",
    "\n",
    "Suppose `w` is a (512, 784) rank 2 tensor , `x` is a (784, ) rank 1 tensor and `b` is (512,)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a67ae3-ecb8-4f6f-abdb-c31da0761027",
   "metadata": {
    "id": "df6e1c25-7b41-4907-9f14-e3574bfebeb8"
   },
   "source": [
    "The result of `dot(w, x)` is a (512, ) tensor.\n",
    "\n",
    "Element `i` of `dot(w, x)` is:\n",
    "\n",
    "\\begin{align*}\n",
    "(w \\cdot x)_i &= \\sum_{j=0}^{783} w_{ij}x_j \\\\\n",
    "i &= 0, 1,\\ldots, 511\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c092e-f639-46df-a664-48b2369c3497",
   "metadata": {
    "id": "a45a3f3a-4044-4f95-a175-2a66b05ec1c2"
   },
   "source": [
    "The result of `dot(w, x)` is added element-wise to `b` (they have the same shape) and `relu` is applied to each element.\n",
    "\n",
    "The layer transformation `relu(dot(w, x) + b)` is a composition of elementary tensor operations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840661c-9f9e-4d2a-8b57-4c5914cf3f07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NumPy implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a6539-816a-4409-8ebc-15a8bc0de3f6",
   "metadata": {},
   "source": [
    "### 1. Single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2ef8fd6-a8ac-45ab-945b-0e6271d7cba9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# a three unit layer\n",
    "n_features = 2\n",
    "n_units = 4                                        # example:\n",
    "x = tf.random.normal(shape=(1, n_features))        # (1,2)\n",
    "w = tf.random.normal(shape=(n_features, n_units))  # (2,4) | (2,1) @ (2,4) â†’ (2,4)\n",
    "b = tf.random.normal(shape=(n_units,))             # (4,)  | (2,4) + (4,) â†’ (2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccec2ffb-9fee-4bab-ba56-ebb33d75c5ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "[[-0.3827687  1.073073 ]]\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "505f2230-2bd8-4b05-bbc5-7c082695a53e",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "[[-1.2287264  -1.3801564   0.4588752  -0.72386575]\n",
      " [-0.46529594 -0.05570686 -0.73343885 -0.713819  ]]\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "803786ee-a140-46fd-b0fc-cccfa8c22b8e",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "[-0.04395255 -1.824693    1.409051   -0.15460077]\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009a5b3-35a2-46c2-afb3-c78291231138",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now our affine transformation followed by `relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6fa049c6-ad3b-40df-b772-d27ae07e247d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "[[-0.02897854  0.46850315 -0.9626765  -0.4889068 ]]\n"
     ]
    }
   ],
   "source": [
    "y = x @ w # now our input x has been *projected* into an 4-dimensional space\n",
    "print(y.shape)\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dae4d706-007e-4815-b7b5-c168f9e360a7",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "[[-0.07293109 -1.3561898   0.44637442 -0.6435076 ]]\n"
     ]
    }
   ],
   "source": [
    "y += b # adding the bias elementwise\n",
    "print(y.shape)\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60066b40-4668-4c6d-809a-1f34ca72e621",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "[[0.         0.         0.44637442 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.nn.relu(y) # applying ReLU elementwise\n",
    "print(a.shape)\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d171a8-a4ef-42a6-b5a6-d9daae0236d2",
   "metadata": {},
   "source": [
    "#### 2. Mini-batch of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99c9fa1e-1509-48b8-bc7b-46db9d33c1e5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# a three unit layer\n",
    "n_features = 2\n",
    "batch_size = 3\n",
    "n_units = 4                                          # example:\n",
    "x = tf.random.normal(shape=(batch_size, n_features)) # (3,2)\n",
    "w = tf.random.normal(shape=(n_features, n_units))    # (2,4) | (3,2) @ (2,4) â†’ (3,4)\n",
    "b = tf.random.normal(shape=(n_units, ))              # (4,)  | (3,4) + (4,) â†’ (3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af52180b-4e27-428b-84a9-02515cb9a41e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[-0.7478592  0.4506009]\n",
      " [ 0.8273411 -0.3064153]\n",
      " [-1.1388956 -0.6804521]]\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e0cfbec-2deb-4bb5-b0f0-a2399cd91f15",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "[[-0.9080192  -0.5993537   0.6183418   0.24517813]\n",
      " [-0.27917686  1.1274191   0.67797095  1.0029206 ]]\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "495a6a18-525d-4136-99e9-7b468abed327",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "[ 2.4454253  -0.586603    1.2240415  -0.71546394]\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01bd369-0af6-46cd-9659-b2d2ef8c49bd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now our affine transformation followed by `relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa989ba2-9ffc-42f4-aa9f-4126f3e5d871",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "[[ 0.55327314  0.9562482  -0.15693828  0.2685582 ]\n",
      " [-0.6656975  -0.8413284   0.3038389  -0.10446427]\n",
      " [ 1.2241055  -0.08455344 -1.1655536  -0.96167177]]\n"
     ]
    }
   ],
   "source": [
    "y = x @ w # now our input x has been *projected* into an 4-dimensional space\n",
    "print(y.shape)\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "493f13cc-0f18-4a7c-b576-cf37450311b9",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "[[ 2.9986985   0.36964524  1.0671031  -0.44690573]\n",
      " [ 1.7797277  -1.4279313   1.5278804  -0.8199282 ]\n",
      " [ 3.6695309  -0.6711564   0.05848789 -1.6771357 ]]\n"
     ]
    }
   ],
   "source": [
    "y += b # adding the bias elementwise (broadcasting)\n",
    "print(y.shape)\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a24a7f67-faec-49c7-a5b1-8c0edaa006a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "[[2.9986985  0.36964524 1.0671031  0.        ]\n",
      " [1.7797277  0.         1.5278804  0.        ]\n",
      " [3.6695309  0.         0.05848789 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.nn.relu(y) # applying ReLU elementwise\n",
    "print(a.shape)\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10879b9a-88db-4699-b1b8-58fbcbb96b77",
   "metadata": {},
   "source": [
    "## Keras implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21917f-6121-4ba0-8ae1-e5df3570afd8",
   "metadata": {
    "id": "00d3372e-5114-4df3-b062-bc8d244a18f6"
   },
   "source": [
    "```python\n",
    "keras.layers.Dense(16, activation=\"relu\")\n",
    "``` \n",
    "implements: \n",
    "\n",
    "```python\n",
    "output = relu(dot(w, input) + b)\n",
    "```\n",
    "\n",
    "- This layer transforms an input tensor into a 1D tensor of shape (16,) â€“ a 16-dimensional vector.\n",
    "\n",
    "- **Representational space** = **(hidden) units/neurons** = **spatial dimensions** = 16.\n",
    "\n",
    "- Performs a **geometric transformation** resulting in a **point in 16 dimensional space**.\n",
    "\n",
    "- Because we always process a **batch**, the dimension you'll see will be 2D: (batch_size, 16).\n",
    "\n",
    "Think: 16 units â†’ 16-dimensional output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7b173-02a9-4b80-9756-1c02e82a58fe",
   "metadata": {
    "id": "a916903c"
   },
   "source": [
    "### 1. One sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283d91b-cc5b-4e5c-8082-2f1d0e732e58",
   "metadata": {
    "id": "a916903c"
   },
   "source": [
    "| parameter |  shape | note |\n",
    "| --- |  :--- | :--- |\n",
    "| input| `(1,10000)`  ||\n",
    "| weights| `(10000,16)`  ||\n",
    "| $xW$| `(1,16)` | `(1,10000)`$\\times$`(10000,16)` â†’ `(1,16)` |\n",
    "| bias|`(16,)`  | added elementwise + broadcasting |\n",
    "| output| `(1,16)`  | activation also elementwise |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515fc623-0332-40e2-93b7-0d2e987f6089",
   "metadata": {
    "id": "caf6e60b"
   },
   "source": [
    "### 2. Mini-batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b572d1-4463-4fe7-bea1-74372b9ca949",
   "metadata": {
    "id": "caf6e60b"
   },
   "source": [
    "| parameter |  shape | note |\n",
    "| --- |  :--- | :--- |\n",
    "| input| `(batch_size,10000)`  ||\n",
    "| weights| `(10000,16)`  ||\n",
    "| $xW$| `(16,batch_size)` | `(batch_size,10000)`$\\times$`(10000,16)` â†’ `(batch_size,16)` |\n",
    "| bias|`(16,)`  | added elementwise + broadcasting|\n",
    "| output| `(batch_size,16)`  |  activation also elementwise |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa630d87-9103-4758-9ef5-ee959a2f34b6",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c424d67-48d5-4117-8d58-68473bc3c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((3, 10000))\n",
    "l = tf.keras.layers.Dense(16, activation=\"relu\")\n",
    "a = l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12dd5a0c-7ebc-4488-82c7-d2166f47a546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 16])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da3a4cc5-f091-4caf-834c-d201f85554cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10000, 16]), TensorShape([16]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights, biases\n",
    "l.weights[0].shape, l.weights[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eca309-6958-4bb7-94c7-7b6938c5601f",
   "metadata": {},
   "source": [
    "### Note: calculating the number of parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d603ab-6ac6-4483-833d-c5c809dc0492",
   "metadata": {
    "id": "b723e4d5"
   },
   "source": [
    "$$\n",
    "\\bbox[5px,border:2px solid red]\n",
    "{\n",
    "\\mathrm{number\\ of\\ params\\ per\\ layer} = \\underbrace{\\mathrm{input\\ dim} \\times \\mathrm{number\\ of\\ units}}_{\\mathrm{weights\\ matrix}}\n",
    "+\n",
    "\\underbrace{\\mathrm{number\\ of\\ units}}_{\\mathrm{bias\\ vector}}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9fc026f7-c104-42d3-b994-c6beedd46dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,016</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚       \u001b[38;5;34m160,016\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚           \u001b[38;5;34m272\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m170\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,458</span> (626.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160,458\u001b[0m (626.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,458</span> (626.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m160,458\u001b[0m (626.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input((10000,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88fcd506-ecea-449d-8b6c-9e149fc505fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer \t (in, units) \t bias\n",
      "0 \t (10000, 16) \t (16,)\n",
      "1 \t (16, 16) \t (16,)\n",
      "2 \t (16, 10) \t (10,)\n"
     ]
    }
   ],
   "source": [
    "# The weight and bias tensors\n",
    "def print_layer_tensor_shape(layer):\n",
    "    weight_params, bias_params = model.layers[layer].get_weights()\n",
    "    print(layer, \"\\t\", weight_params.shape, \"\\t\", bias_params.shape)\n",
    "\n",
    "print(\"layer\", \"\\t\", \"(in, units)\", \"\\t\", \"bias\")\n",
    "print_layer_tensor_shape(layer=0)\n",
    "print_layer_tensor_shape(layer=1)\n",
    "print_layer_tensor_shape(layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f81d819c-0cad-437a-bb88-d4c0d3c48adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160,458\n"
     ]
    }
   ],
   "source": [
    "# same as above\n",
    "print(f\"{(10000 * 16 + 16) + (16 * 16 + 16) + (16 * 10 + 10):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78361e-e6c6-4e83-aa01-839db53a75f8",
   "metadata": {
    "id": "0f5e3f51-203c-45fe-9996-b6b8bf47dbd0"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a12c8-7150-4623-9534-6b598e2a1338",
   "metadata": {
    "id": "0f5e3f51-203c-45fe-9996-b6b8bf47dbd0"
   },
   "source": [
    "# Geometric interpretation of tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe4f8d",
   "metadata": {
    "id": "01fe4f8d"
   },
   "source": [
    "Neural networks are of course transforming data into useful representations, but one way I like to think about that\n",
    "is that they **transform space itself** to achieve their goals.\n",
    "\n",
    "Indeed, numerical tensor elements can be interpreted not only as:\n",
    "\n",
    "- coordinates in a (high-dimensional) real space;  \n",
    "- but also as **linear transformations** in this space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f888e-6c2a-4538-b6a1-b6e38eac3008",
   "metadata": {
    "id": "475f888e-6c2a-4538-b6a1-b6e38eac3008"
   },
   "source": [
    "A function is linear if:\n",
    "1. $f(x + y) = f(x) + f(y) \\quad \\text{(additivity)}$\n",
    "2. $f(ax) = af(x) \\quad \\text{(homogeneity)}$\n",
    "\n",
    "Otherwise it is nonlinear.\n",
    "\n",
    "Intuitively, this is equivalent to:\n",
    "- **squishing** or **stretching**;  \n",
    "- **performing rotations** or a **shear**;  \n",
    "- (all **straight lines** remain straight);  \n",
    "- (and the **origin remains fixed**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b054e",
   "metadata": {
    "id": "d11b054e"
   },
   "source": [
    "For example, a rotation:\n",
    "\n",
    "<!-- ![Figure showing the effect of a rotation matrix visually](images/chollet/figure2.10.png) -->\n",
    "<img alt=\"Figure showing the effect of a rotation matrix visually\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/chollet/figure2.10.png\">\n",
    "\n",
    "<small>[DLWP](https://deeplearningwithpython.io/chapters/chapter02_mathematical-building-blocks/#geometric-interpretation-of-tensor-operations), Chapter 2, Figure 2.10</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ddc259-8e9b-4b75-8023-4ef0b6400845",
   "metadata": {
    "id": "65ddc259-8e9b-4b75-8023-4ef0b6400845"
   },
   "source": [
    "Or this:\n",
    "\n",
    "<!-- ![Figure showing the effect of a matrix flipping and shrinking the y dimension (vertical mirroring)](images/chollet/figure2.11.png) -->\n",
    "<img alt=\"Figure showing the effect of a matrix flipping and shrinking the y dimension (vertical mirroring)\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/chollet/figure2.11.png\">\n",
    "\n",
    "<small>[DLWP](https://deeplearningwithpython.io/chapters/chapter02_mathematical-building-blocks/#geometric-interpretation-of-tensor-operations), Chapter 2, Figure 2.11</small>\n",
    "\n",
    "<!-- \\begin{align*}\n",
    "w\\cdot x = \\begin{pmatrix} \\cos \\theta & -\\sin \\theta \\\\ \\sin \\theta & \\cos \\theta \\end{pmatrix}\n",
    "\\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix} x_1 \\cos \\theta - x_2 \\sin \\theta \\\\ x_1 \\sin \\theta + y_2 \\cos \\theta \\end{pmatrix}\n",
    "\\end{align*} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72980b6",
   "metadata": {
    "id": "a72980b6"
   },
   "source": [
    "$w \\cdot x$ is a linear transformation.\n",
    "\n",
    "If you add a bias, $wx + b$, this is no longer linear, but **affine**: the origin does not stay where it is. (Same as linear transformations **plus** translations.)\n",
    "\n",
    "##### Note\n",
    "\n",
    "In the deep learning world, *often* you will only hear **linear** to describe these transformations, even if **affine** is the rigorous mathematical concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d82e0f",
   "metadata": {
    "id": "a0d82e0f"
   },
   "source": [
    "<!-- ![Figuring showing vector addition as translation](images/chollet/figure2.9.png) -->\n",
    "<img alt=\"Figuring showing vector addition as translation\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/chollet/figure2.9.png\">\n",
    "\n",
    "<small>[DLWP](https://deeplearningwithpython.io/chapters/chapter02_mathematical-building-blocks/#geometric-interpretation-of-tensor-operations), Chapter 2, Figure 2.9</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061603b",
   "metadata": {
    "id": "7061603b"
   },
   "source": [
    "<!-- ![Figure showing the combined effect of an affine transformation Wx + b](images/chollet/figure2.12.png) -->\n",
    "<img alt=\"Figure showing the combined effect of an affine transformation Wx + b\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/chollet/figure2.12.png\">\n",
    "\n",
    "<small>[DLWP](https://deeplearningwithpython.io/chapters/chapter02_mathematical-building-blocks/#geometric-interpretation-of-tensor-operations), Chapter 2, Figure 2.12</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e0a21c-3093-48a7-b564-141e9fd609a9",
   "metadata": {
    "id": "35e0a21c-3093-48a7-b564-141e9fd609a9"
   },
   "source": [
    "Each layer in a neural network performs a non-linear data transformation:\n",
    "\n",
    "$$f(w\\cdot x + b)$$\n",
    "\n",
    "where $f$ is the **activation function** and $w \\cdot x + b$ is an affine transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24f500",
   "metadata": {
    "id": "7a24f500"
   },
   "source": [
    "<!-- ![Figure showing the effect of the the same affine transform, followed by a nonlinearity (the rectangle is first deformed 'linearly', then part of it is 'cut', since projected onto 0](images/chollet/figure2.13.png) -->\n",
    "<img alt=\"Figure showing the effect of the the same affine transform, followed by a nonlinearity (the rectangle is first deformed 'linearly', then part of it is 'cut', since projected onto 0\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/chollet/figure2.13.png\">\n",
    "\n",
    "<small>[DLWP](https://deeplearningwithpython.io/chapters/chapter02_mathematical-building-blocks/#geometric-interpretation-of-tensor-operations), Chapter 2, Figure 2.13</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12b324-fe2c-4a9a-aa79-f3aa058408e1",
   "metadata": {
    "id": "1e12b324-fe2c-4a9a-aa79-f3aa058408e1"
   },
   "source": [
    "The network as a whole, in a series of linear, affine and non-linear transformations  implements a *complex transformation on a high dimensional geometric object* (the data).\n",
    "\n",
    "The overall function of the network is **composed of a series of simpler transformations**.\n",
    "\n",
    "The network unfolds complex data into something simple and meaningful (a representation where you can easily separate your classes...). Chollet's image: unfolding a paper sheet, crumpled into a 1000 dimensional ball.\n",
    "\n",
    "<!-- ![Figure showing a ball of paper first crumpled, then uncrumpled, as an image for the effect of a neural network on data](images/chollet/figure2.14.png) -->\n",
    "<img alt=\"Figure showing a ball of paper first crumpled, then uncrumpled, as an image for the effect of a neural network on data\" style=\"\" src=\"https://raw.githubusercontent.com/jchwenger/DLWP/main/lectures/02/images/chollet/figure2.14.png\">\n",
    "\n",
    "<small>[DLWP](https://deeplearningwithpython.io/chapters/chapter02_mathematical-building-blocks/#the-gears-of-neural-networks-tensor-operations), Chapter 2, Figure 2.14</small>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
